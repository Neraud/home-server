---

# To avoid loops inside elasticsearch
_elasticsearch_var_loader:
  base_image:
    name: "amazon/opendistro-for-elasticsearch"
    tag: "1.13.2"
  namespace: "logging-elasticsearch"
  cluster_name: k8s-logs

elasticsearch:
  enabled: "{{ elasticsearch_enabled | default(True) }}"

  namespace: "{{ _elasticsearch_var_loader.namespace }}"
  base_image: "{{ _elasticsearch_var_loader.base_image }}"
  
  labels_def:
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/component: elasticsearch
    app.kubernetes.io/instance: "{{ _elasticsearch_var_loader.cluster_name }}"

  labels_desc:
    app.kubernetes.io/version: "{{ _elasticsearch_var_loader.base_image.tag }}"
    app.kubernetes.io/part-of: elasticsearch
  
  container:
    image: "{{ docker_private_registry.url }}/{{ _elasticsearch_var_loader.base_image.name | regex_replace('.*/', '') }}:{{ _elasticsearch_var_loader.base_image.tag }}"
    requests_cpu: "{{ elasticsearch_container_requests_cpu | default('250m') }}"
    requests_memory: "{{ elasticsearch_container_requests_memory | default('1024Mi') }}"
    limits_cpu: "{{ elasticsearch_container_limits_cpu | default('750m') }}"
    limits_memory: "{{ elasticsearch_container_limits_memory | default('1024Mi') }}"
  
  servername: "{{ elasticsearch_servername | default('elasticsearch.' + _elasticsearch_var_loader.namespace + '.svc.cluster.local') }}"

  context_path: "{{ elasticsearch_context_path | default('/') }}"
  replicas: "{{ elasticsearch_replicas | default(1) }}"
  cluster_name: "{{ _elasticsearch_var_loader.cluster_name }}"
  max_java_memory: "{{ elasticsearch_max_java_memory | default('512m') }}"

  logstash_policy:
    name: "hot-cold-delete"
    cold_age: "{{ elasticsearch_logstash_policy_cold_age | default('2d') }}"
    delete_age: "{{ elasticsearch_logstash_policy_delete_age | default('7d') }}"

  # TODO : these user / passwords can't easily be changed without wiping the ES cluster.
  # We probably need to run /usr/share/elasticsearch/plugins/opendistro_security/tools/securityadmin.sh inside the container
  internal_users: "{{ elasticsearch_internal_users | default([]) }}"

  admin_user:
    user: "{{ elasticsearch_admin_user_user | default('admin') }}"
    password: "{{ elasticsearch_admin_user_password | default(['password']) }}"

  ldap:
    servername: "{{ elasticsearch_ldap_servername | default(openldap.ldap.servername) }}"
    manager_dn: "{{ elasticsearch_ldap_manager_dn | default(openldap.ldap.readonly_user_dn) }}"
    manager_password: "{{ elasticsearch_ldap_manager_password | default(openldap.ldap.readonly_user_password) }}"
    users_dn: "{{ elasticsearch_ldap_users_dn | default(openldap.ldap.structure_users_ou_dn) }}"
    group: "{{ elasticsearch_ldap_group }}"
    roles_dn: "{{ elasticsearch_ldap_roles_dn }}"



# To avoid loops inside elasticsearch_exporter
_elasticsearch_exporter_var_loader:
  base_image:
    name: "justwatch/elasticsearch_exporter"
    tag: "1.1.0"

elasticsearch_exporter:
  base_image: "{{ _elasticsearch_exporter_var_loader.base_image }}"
  
  labels_def:
    app.kubernetes.io/name: elasticsearch
    app.kubernetes.io/component: exporter

  labels_desc:
    app.kubernetes.io/version: "{{ _elasticsearch_exporter_var_loader.base_image.tag }}"
    app.kubernetes.io/part-of: elasticsearch
  
  container:
    image: "{{ docker_private_registry.url }}/{{ _elasticsearch_exporter_var_loader.base_image.name | regex_replace('.*/', '') }}:{{ _elasticsearch_exporter_var_loader.base_image.tag }}"
    requests_cpu: "{{ elasticsearch_exporter_container_requests_cpu | default('25m') }}"
    requests_memory: "{{ elasticsearch_exporter_container_requests_memory | default('64Mi') }}"
    limits_cpu: "{{ elasticsearch_exporter_container_limits_cpu | default('100m') }}"
    limits_memory: "{{ elasticsearch_exporter_container_limits_memory | default('128Mi') }}"


  user: "{{ elasticsearch_exporter_user | default('exporter') }}"
  password: "{{ elasticsearch_exporter_password | default('password') }}"
